{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import json\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csc_matrix\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from networkx import to_numpy_matrix, degree_centrality, betweenness_centrality, shortest_path_length,read_edgelist, set_node_attributes\n",
    "from sklearn.metrics import average_precision_score,recall_score,precision_score,accuracy_score\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import time\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from utlis import get_spectrum_embedding,load_data\n",
    "from sklearn import preprocessing\n",
    "from scipy.sparse.linalg import inv,eigs\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from scipy.sparse import csc_matrix\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score,recall_score,precision_score,accuracy_score\n",
    "from plot_utlis import scatter_plot\n",
    "from train_utlis import train,evaluate, loss,accuracy,get_train_test_set,fit_predict_lr,get_tsne_results\n",
    "from models import *\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from utlis import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tsne_results(features,n_components=2):\n",
    "    tsne = TSNE(n_components=n_components, verbose=0, perplexity= 25, n_iter=500)\n",
    "    tsne_results=tsne.fit_transform(features)\n",
    "    return tsne_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "data_set='pubmed'\n",
    "data,A_norm, features, label_lists, _,_,_=load_data(data_set)\n",
    "abel_lists=label_lists.numpy()\n",
    "#data ,features, label_lists=load_data(data_set)\n",
    "\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "tsne_results=get_tsne_results(features)\n",
    "print(\"Training time\",time.time()-time_start)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test =get_train_test_set(tsne_results, label_lists, train_test_split_coef=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc:  0.5939897292842199\n",
      "Training precision:  0.5924447294932744 Training recall:  0.5939897292842199\n",
      "Test acc:  0.5816430020283976\n",
      "Testing precision:  0.5791011575811594 Training recall:  0.5816430020283976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5939897292842199, 0.5816430020283976)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train test split\n",
    "\n",
    "fit_predict_lr(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrum Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 1.1480820178985596\n",
      "Train acc:  0.7879287389843403\n",
      "Training precision:  0.7876430907366762 Training recall:  0.7879287389843403\n",
      "Test acc:  0.7849898580121704\n",
      "Testing precision:  0.787814941403923 Training recall:  0.7849898580121704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7879287389843403, 0.7849898580121704)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_set='pubmed'\n",
    "\n",
    "data,A_norm, features, label_lists, _,_,_=load_data(data_set)\n",
    "label_lists=label_lists.numpy()\n",
    "k=31\n",
    "time_start = time.time()\n",
    "\n",
    "sp_results=get_spectrum_embedding(data,k)\n",
    "\n",
    "print(\"Training time\",time.time()-time_start)\n",
    "x_train, x_test, y_train, y_test =get_train_test_set(sp_results, label_lists, train_test_split_coef=0.8)\n",
    "\n",
    "fit_predict_lr(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_results=get_tsne_results(sp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot=scatter_plot(tsne_results,label_lists,data_set=data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data_set='github_user'\n",
    "# data, features, label_lists=load_data(data_set)\n",
    "\n",
    "# k=2\n",
    "\n",
    "# time_start = time.time()\n",
    "\n",
    "# sp_results=get_spectrum_embedding(data,k)\n",
    "\n",
    "# print(\"Training time\",time.time()-time_start)\n",
    "# x_train, x_test, y_train, y_test =get_train_test_set(sp_results, label_lists, train_test_split_coef=0.8)\n",
    "# fit_predict_lr(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot=scatter_plot(sp_results,label_lists,data_set=data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Convolution Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET=['cora','citeseer','pubmed']\n",
    "dataset_str='cora'\n",
    "_,A_norm, features, labels, idx_train,idx_test,idx_val=load_data(dataset_str)\n",
    "\n",
    "no_cuda= False,\n",
    "seed=42\n",
    "epochs=400\n",
    "lr=0.01\n",
    "weight_decay=5e-4\n",
    "hidden=16\n",
    "dropout=0.5\n",
    "fast_training=False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
    "early_stop_epoch=10\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataset_str='github_user'\n",
    "# data,features, labels=load_data(dataset_str)\n",
    "\n",
    "\n",
    "# A=get_adjacency_matrix(data)\n",
    "\n",
    "# A_norm=preprocess_adj(A)\n",
    "\n",
    "\n",
    "# no_cuda= False,\n",
    "# seed=42\n",
    "# epochs=400\n",
    "# lr=0.02\n",
    "# weight_decay=0\n",
    "# hidden=32\n",
    "# dropout=0\n",
    "# fast_training=False\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
    "# early_stop_epoch=10\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_idx=np.arange(len(features)).reshape(-1,1)\n",
    "labels=torch.LongTensor(labels)\n",
    "features=torch.FloatTensor(features)\n",
    "label_lists=labels.numpy()\n",
    "x_train, x_test, y_train, y_test =get_train_test_set(full_idx, label_lists, train_test_split_coef=0.8)\n",
    "\n",
    "idx_train = torch.LongTensor(x_train.reshape(-1))\n",
    "idx_test = torch.LongTensor(x_test.reshape(-1))\n",
    "\n",
    "\n",
    "model = SimpleGCN(adj=A_norm,nfeat=features.shape[1],\n",
    "            nhid=hidden,\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=dropout,res_connection=True,get_hidden=True).to(device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618e458130844cd3a95fe98e130e157c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stop at Epoch 202\n",
      "Optimization Finished!\n",
      "Total Training time elapsed: 5.8745s\n",
      "Start Inference:\n",
      "Train: loss;: 0.2536 acc: 0.9626\n",
      "Test: loss;: 0.4850 acc: 0.8679\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train model\n",
    "t_total = time.time()\n",
    "epoch_no_improvement=0\n",
    "min_val_loss=float('inf')\n",
    "\n",
    "# init_loss_train, init_acc_train,_=evaluate(model,features,idx_train,labels)\n",
    "# training_loss_list=[init_loss_train]\n",
    "# training_error_list=[1-init_acc_train]\n",
    "       \n",
    "# if not fast_training:\n",
    "#     init_loss_val, init_acc_val,_=evaluate(model,features,idx_val,labels)\n",
    "#     validation_loss_list=[init_loss_val]\n",
    "#     validation_error_list=[1-init_acc_val]\n",
    "\n",
    "for epoch in tqdm_notebook(range(epochs)):\n",
    "    \n",
    "    loss_train,acc_train,output,hidden=train(model,features,idx_train,labels,optimizer)\n",
    "    \n",
    "    #print('Epoch: {:04d} ,loss_train: {:.4f},acc_train: {:.4f}\\n'.format(epoch+1,loss_train,acc_train),end=\"\")\n",
    "          \n",
    "    if not fast_training:\n",
    "        \n",
    "        loss_val,acc_val,output,hidden=evaluate(model,features,idx_test,labels)\n",
    "  \n",
    "       #print('Eval: ,loss_val: {:.4f},acc_val: {:.4f}\\n'.format(loss_val,acc_val),end=\"\")\n",
    "        if loss_val<min_val_loss:\n",
    "          epoch_no_improvement=0\n",
    "          min_val_loss = loss_val\n",
    "        else:\n",
    "          epoch_no_improvement+=1\n",
    "        \n",
    "        if epoch_no_improvement==early_stop_epoch:\n",
    "          print('Early Stop at Epoch %d'%(epoch))\n",
    "          break\n",
    "        #print()\n",
    "          \n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total Training time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "\n",
    "#test\n",
    "print(\"Start Inference:\")\n",
    "\n",
    "\n",
    "loss_trn,acc_trn,_,hidden=evaluate(model,features,idx_train,labels)\n",
    "print('Train:','loss;: {:.4f}'.format( loss_trn),\n",
    "          'acc: {:.4f}'.format(acc_trn))\n",
    "\n",
    "\n",
    "loss_test,acc_test,_,_=evaluate(model,features,idx_test,labels)\n",
    "print('Test:','loss;: {:.4f}'.format( loss_test),\n",
    "          'acc: {:.4f}'.format(acc_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 76 nearest neighbors...\n",
      "[t-SNE] Indexed 19717 samples in 0.026s...\n",
      "[t-SNE] Computed neighbors for 19717 samples in 1.095s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 19717\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 19717\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 19717\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 19717\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 19717\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 19717\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 19717\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 19717\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 19717\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 19717\n",
      "[t-SNE] Computed conditional probabilities for sample 11000 / 19717\n",
      "[t-SNE] Computed conditional probabilities for sample 12000 / 19717\n",
      "[t-SNE] Computed conditional probabilities for sample 13000 / 19717\n",
      "[t-SNE] Computed conditional probabilities for sample 14000 / 19717\n",
      "[t-SNE] Computed conditional probabilities for sample 15000 / 19717\n",
      "[t-SNE] Computed conditional probabilities for sample 16000 / 19717\n",
      "[t-SNE] Computed conditional probabilities for sample 17000 / 19717\n",
      "[t-SNE] Computed conditional probabilities for sample 18000 / 19717\n",
      "[t-SNE] Computed conditional probabilities for sample 19000 / 19717\n",
      "[t-SNE] Computed conditional probabilities for sample 19717 / 19717\n",
      "[t-SNE] Mean sigma: 0.007554\n",
      "[t-SNE] Computed conditional probabilities in 1.116s\n",
      "[t-SNE] Iteration 50: error = 107.7796555, gradient norm = 0.0041411 (50 iterations in 18.705s)\n",
      "[t-SNE] Iteration 100: error = 87.9855652, gradient norm = 0.0033272 (50 iterations in 11.672s)\n",
      "[t-SNE] Iteration 150: error = 82.9010315, gradient norm = 0.0020199 (50 iterations in 8.077s)\n",
      "[t-SNE] Iteration 200: error = 80.4632492, gradient norm = 0.0015364 (50 iterations in 8.250s)\n",
      "[t-SNE] Iteration 250: error = 78.9053802, gradient norm = 0.0009672 (50 iterations in 8.132s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 78.905380\n",
      "[t-SNE] Iteration 300: error = 3.3970723, gradient norm = 0.0012604 (50 iterations in 7.383s)\n",
      "[t-SNE] Iteration 350: error = 2.7734778, gradient norm = 0.0006761 (50 iterations in 6.957s)\n",
      "[t-SNE] Iteration 400: error = 2.4048054, gradient norm = 0.0004319 (50 iterations in 6.854s)\n",
      "[t-SNE] Iteration 450: error = 2.1662235, gradient norm = 0.0003067 (50 iterations in 6.697s)\n",
      "[t-SNE] Iteration 500: error = 1.9998299, gradient norm = 0.0002323 (50 iterations in 6.607s)\n",
      "[t-SNE] KL divergence after 500 iterations: 1.999830\n"
     ]
    }
   ],
   "source": [
    "tsne_results=get_tsne_results(hidden.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot=scatter_plot(tsne_results,label_lists,data_set=dataset_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
