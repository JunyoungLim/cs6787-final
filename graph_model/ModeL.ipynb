{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import json\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csc_matrix\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from networkx import to_numpy_matrix, degree_centrality, betweenness_centrality, shortest_path_length,read_edgelist, set_node_attributes\n",
    "from sklearn.metrics import average_precision_score,recall_score,precision_score,accuracy_score\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import time\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from utlis import get_spectrum_embedding,load_data\n",
    "from sklearn import preprocessing\n",
    "from scipy.sparse.linalg import inv,eigs\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from scipy.sparse import csc_matrix\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score,recall_score,precision_score,accuracy_score\n",
    "from plot_utlis import scatter_plot\n",
    "from train_utlis import train,evaluate, loss,accuracy,get_train_test_set,fit_predict_lr,get_tsne_results\n",
    "from models import *\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from utlis import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Val, Test Dataset Size for dataset cora\n",
      "Training set 140, Validation Set 500, Test Set 1000\n",
      "Train, Val, Test Dataset Size for dataset citeseer\n",
      "Training set 120, Validation Set 500, Test Set 1000\n",
      "Train, Val, Test Dataset Size for dataset pubmed\n",
      "Training set 60, Validation Set 500, Test Set 1000\n",
      "Train, Val, Test Dataset Size for dataset github_user\n",
      "Training set 7539, Validation Set 30161, Test Set 30161\n"
     ]
    }
   ],
   "source": [
    "DATASET=['cora','citeseer','pubmed','github_user']\n",
    "for dataset_str in DATASET:\n",
    "    G,A_norm, features, labels, idx_train,idx_test,idx_val=load_data(dataset_str)\n",
    "\n",
    "    print(\"Train, Val, Test Dataset Size for dataset {}\".format(dataset_str))\n",
    "    print(\"Training set {}, Validation Set {}, Test Set {}\".format(len(idx_train),len(idx_val),len(idx_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,features,labels=load_data('karate4')\n",
    "A = nx.adjacency_matrix(data)\n",
    "A_norm = preprocess_adj(A)\n",
    "n_labels=len(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A_norm=sparse_mx_to_torch_sparse_tensor(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=torch.LongTensor(labels)\n",
    "features=sparse.csr_matrix(np.eye(*A.shape)).todense()\n",
    "\n",
    "\n",
    "\n",
    "features=torch.FloatTensor(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train=torch.LongTensor([0,33,6,27])\n",
    "idx_test=torch.LongTensor(range(34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ToyGCN(nn.Module):\n",
    "    def __init__(self, adj, nfeat, nhid, nclass, dropout, res_connection=True,get_hidden=False):\n",
    "        super(ToyGCN, self).__init__()\n",
    "        self.adj = adj\n",
    "        self.gc1 = GCNLayer(self.adj, nfeat, nhid, res_connection=res_connection)\n",
    "        self.gc2 = GCNLayer(self.adj, nhid, 2, res_connection=res_connection)\n",
    "        self.gc3 = GCNLayer(self.adj, 2, nclass, res_connection=res_connection)\n",
    "        self.dropout_rate = dropout\n",
    "        self.relu = nn.ReLU()\n",
    "        self.get_hidden=get_hidden\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.gc1(x)\n",
    "        x = self.relu(x)\n",
    "        #x = F.dropout(x, self.dropout_rate, self.training)\n",
    "        hidden = self.gc2(x)\n",
    "        x = self.relu(hidden)\n",
    "        \n",
    "        #x = F.dropout(x, self.dropout_rate, self.training)\n",
    "        x = self.gc3(x)\n",
    "        \n",
    "        if self.get_hidden:\n",
    "            return x,hidden\n",
    "        return x\n",
    "\n",
    "# class Graph_Conv(nn.Module):\n",
    "#     def __init__(self, adj,nfeat, nhid, nclass, dropout,res_connection=True,get_hidden=False):\n",
    "#         super(Graph_Conv, self).__init__()\n",
    "#         self.adj=adj\n",
    "#         self.gc1 = GCNLayer(self.adj,nfeat, nhid,res_connection=res_connection)\n",
    "#         self.gc2 = GCNLayer(self.adj,nhid, nclass,res_connection=res_connection)\n",
    "# #         self.gc3 = GCNLayer(self.adj,2, nclass,res_connection=res_connection)\n",
    "#         self.dropout_rate = dropout\n",
    "#         self.relu=nn.ReLU()\n",
    "#         self.loss_fuc=nn.CrossEntropyLoss(reduction='mean')\n",
    "#         self.get_hidden=False\n",
    "        \n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.relu(self.gc1(x))\n",
    "# #         x =F.dropout(x, self.dropout_rate, self.training)\n",
    "# #         nf = self.relu(self.gc2(x))\n",
    "# #         print(nf.shape)\n",
    "#         x =F.dropout(x, self.dropout_rate, self.training)\n",
    "#         x = self.gc2(x)\n",
    "#         return x,x\n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sp(model,features,idx_train,labels,optimizer):\n",
    "  \n",
    "    model.train()\n",
    "    if model.get_hidden:\n",
    "        output,hidden = model(features)\n",
    "    else:\n",
    "        output= model(features)\n",
    "        \n",
    "    loss_train=loss(output,labels,idx_train)\n",
    "    acc_train = accuracy(output, labels,idx_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss_train.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    if model.get_hidden:\n",
    "        return loss_train.item(),acc_train.item(),output,hidden\n",
    "   \n",
    "    return loss_train.item(),acc_train.item(),output\n",
    "\n",
    "\n",
    "def evaluate_sp(model,features,idx,labels):\n",
    "    model.eval()\n",
    "    if model.get_hidden:\n",
    "        output,hidden = model(features)\n",
    "    else:\n",
    "        output= model(features)\n",
    "\n",
    "    loss_ =loss(output,labels,idx)\n",
    "    acc_ = accuracy(output, labels,idx)\n",
    "    \n",
    "    \n",
    "    if model.get_hidden:\n",
    "        return loss_.item(),acc_.item(),output,hidden\n",
    "\n",
    "    return loss_.item(),acc_.item(),output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6826f5b0b1f4683853d3527e32b7f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization Finished!\n",
      "Total Training time elapsed: 0.5695s\n",
      "Start Inference:\n",
      "Train: loss;: 0.0016 acc: 1.0000\n",
      "Test: loss;: 0.0016 acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "no_cuda= False,\n",
    "seed=42\n",
    "epochs=300\n",
    "lr=0.02\n",
    "weight_decay=0\n",
    "hidden=32\n",
    "dropout=0\n",
    "fast_training=False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
    "early_stop_epoch=5000\n",
    "\n",
    "\n",
    "model = ToyGCN(adj=A_norm,nfeat=features.shape[1],\n",
    "            nhid=hidden,\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=dropout,res_connection=True,get_hidden=True).to(device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Train model\n",
    "t_total = time.time()\n",
    "\n",
    "min_val_loss=float('inf')\n",
    "feature_representation=[]\n",
    "_,_,_,hidden=evaluate_sp(model,features,idx_train,labels)\n",
    "feature_representation.append(hidden)\n",
    "for epoch in tqdm_notebook(range(epochs)):\n",
    "    loss_train,acc_train,output,hidden=train_sp(model,features,idx_test,labels,optimizer)\n",
    "    feature_representation.append(hidden)\n",
    "    if not fast_training:\n",
    "        \n",
    "        loss_val,acc_val,output,hidden=evaluate_sp(model,features,idx_test,labels)\n",
    "  \n",
    "#         print('Eval: ,loss_val: {:.4f},acc_val: {:.4f}\\n'.format(loss_val,acc_val),end=\"\")\n",
    "        if loss_val<min_val_loss:\n",
    "          epoch_no_improvement=0\n",
    "          min_val_loss = loss_val\n",
    "        else:\n",
    "          epoch_no_improvement+=1\n",
    "        \n",
    "        if epoch_no_improvement==early_stop_epoch:\n",
    "          print('Early Stop at Epoch %d'%(epoch))\n",
    "          break\n",
    "        #print()\n",
    "          \n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total Training time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "\n",
    "#test\n",
    "print(\"Start Inference:\")\n",
    "\n",
    "\n",
    "loss_trn,acc_trn,_,hidden=evaluate_sp(model,features,idx_test,labels)\n",
    "print('Train:','loss;: {:.4f}'.format( loss_trn),\n",
    "          'acc: {:.4f}'.format(acc_trn))\n",
    "\n",
    "\n",
    "loss_test,acc_test,_,_=evaluate_sp(model,features,idx_test,labels)\n",
    "print('Test:','loss;: {:.4f}'.format( loss_test),\n",
    "          'acc: {:.4f}'.format(acc_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw( i,epoch):\n",
    "#     if epoch is None:\n",
    "#         epoch = len(feature_representations) - 1\n",
    "\n",
    "    \n",
    "    n_categroy=n_labels\n",
    "    color_list = ['#ff6a00','#ffdd00','#DF2E2E',\"#2E51DF\"]\n",
    "    node_list=data.nodes()\n",
    "\n",
    "\n",
    "    pos = {}\n",
    "    number_of_points=feature_representation[0].size(0)\n",
    "     \n",
    "    for v in range(number_of_points):\n",
    "        pos[v] = feature_representation[ i][v].detach().numpy()\n",
    "#     X = feature_representation[i].detach().numpy()\n",
    "#     X_embedded = TSNE(n_components=2).fit_transform(X)\n",
    "#     for v in range(number_of_points):\n",
    "#         pos[v] = X_embedded[v]\n",
    "    \n",
    "    ax.cla()\n",
    "    ax.axis('off')\n",
    "    #ax.set_title('Epoch: %d' % i)\n",
    "    ax.set_title('Epoch %d'%(int( epoch)))\n",
    "    label_names= ['C'+str(i) for i in range(n_labels)]\n",
    "    \n",
    "\n",
    "    for i_cate in range(n_categroy):\n",
    "        nx.draw_networkx(data, pos, nodelist= [n for j,n in enumerate(node_list) if labels[j]==i_cate],node_color=color_list[i_cate],\n",
    "                with_labels=True, node_size=50, ax=ax,font_size=5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    nx.draw_networkx_edges(data, pos,width=1,alpha=1,edge_color='#DFDEDE')\n",
    "    nx.draw_networkx_nodes(data, pos, nodelist=[0], node_size=350,node_color = color_list[0])\n",
    "    nx.draw_networkx_nodes(data, pos, nodelist=[33], node_size=350,node_color = color_list[1])\n",
    "    nx.draw_networkx_nodes(data, pos, nodelist=[6], node_size=350,node_color = color_list[2])\n",
    "    nx.draw_networkx_nodes(data, pos, nodelist=[27], node_size=350,node_color = color_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "for i,epoch in enumerate([0,50,100,150,200,250,300]):\n",
    "    fig = plt.figure(dpi=150)\n",
    "    fig.clf()\n",
    "    ax = fig.subplots()\n",
    "    draw(i,epoch)\n",
    "    plt.legend(loc=0, fontsize = 'x-small')\n",
    "    plt.axis('on')\n",
    "    plt.show()\n",
    "    #plt.savefig(\"figure_kara_4label/epoch_%d.jpg\"%(int(i)))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genearate Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close()\n",
    "# from matplotlib import animation, rc\n",
    "# # fig = plt.figure(dpi=150)\n",
    "# # fig.clf()\n",
    "# # def anim_init():\n",
    "# #     fig.clear()\n",
    "# ani = animation.FuncAnimation(fig, draw, frames=list(range(0,50)), interval=100,repeat_delay=1000)\n",
    "# from IPython.display import HTML\n",
    "# rc('animation', html='html5')\n",
    "# HTML(ani.to_html5_video())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valina GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def train(idx_train):\n",
    "  \n",
    "    model.train()\n",
    "   \n",
    "    output = model(features)\n",
    "    \n",
    "    loss_train=loss(output,labels,idx_train)\n",
    "    acc_train = accuracy(output, labels,idx_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss_train.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "   \n",
    "    return loss_train.item(),acc_train.item()\n",
    "\n",
    "\n",
    "def evaluate(idx):\n",
    "    model.eval()\n",
    "    output = model(features)\n",
    "    loss_ =loss(output,labels,idx)\n",
    "    acc_ = accuracy(output, labels,idx)\n",
    "\n",
    "    return loss_.item(),acc_.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cora\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4049b0a1e0440eb4d7365a79897fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stop at Epoch 192\n",
      "Optimization Finished!\n",
      "Total Training time elapsed: 4.0947s\n",
      "Start Inference:\n",
      "Train: loss;: 0.2390 acc: 1.0000\n",
      "Test: loss;: 0.7783 acc: 0.8100\n",
      "Total Inference time elapsed: 0.0096s\n",
      "\n",
      "citeseer\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f277d41e13924eaea24a8535e73e55c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stop at Epoch 249\n",
      "Optimization Finished!\n",
      "Total Training time elapsed: 21.0264s\n",
      "Start Inference:\n",
      "Train: loss;: 0.3362 acc: 0.9833\n",
      "Test: loss;: 1.0484 acc: 0.7120\n",
      "Total Inference time elapsed: 0.0388s\n",
      "\n",
      "pubmed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c46b6eba9d640f7995017f4800c5c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stop at Epoch 169\n",
      "Optimization Finished!\n",
      "Total Training time elapsed: 20.2437s\n",
      "Start Inference:\n",
      "Train: loss;: 0.1227 acc: 1.0000\n",
      "Test: loss;: 0.5827 acc: 0.7910\n",
      "Total Inference time elapsed: 0.0531s\n"
     ]
    }
   ],
   "source": [
    "DATASET=['cora','citeseer','pubmed']\n",
    "\n",
    "no_cuda= False,\n",
    "seed=42\n",
    "epochs=400\n",
    "lr=0.01\n",
    "weight_decay=5e-4\n",
    "hidden=16\n",
    "dropout=0.5\n",
    "fast_training=False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
    "early_stop_epoch=10\n",
    "\n",
    "\n",
    "for dataset_str in DATASET:\n",
    "    print()\n",
    "    print(dataset_str)\n",
    "    G,A_norm, features, labels, idx_train,idx_test,idx_val=load_data(dataset_str)\n",
    "    model = SimpleGCN(adj=A_norm,nfeat=features.shape[1],\n",
    "                nhid=hidden,\n",
    "                nclass=labels.max().item() + 1,\n",
    "                dropout=dropout,res_connection=False).to(device=device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "\n",
    "    # Train model\n",
    "    t_total = time.time()\n",
    "    epoch_no_improvement=0\n",
    "    min_val_loss=float('inf')\n",
    "\n",
    "    init_loss_train, init_acc_train=evaluate(idx_train)\n",
    "    training_loss_list=[init_loss_train]\n",
    "    training_error_list=[1-init_acc_train]\n",
    "\n",
    "    if not fast_training:\n",
    "        init_loss_val, init_acc_val=evaluate(idx_val)\n",
    "        validation_loss_list=[init_loss_val]\n",
    "        validation_error_list=[1-init_acc_val]\n",
    "\n",
    "    for epoch in tqdm_notebook(range(epochs)):\n",
    "\n",
    "        loss_train,acc_train=train(idx_train)\n",
    "        training_loss_list.append(loss_train)\n",
    "        training_error_list.append(1-acc_train)\n",
    "        #print('Epoch: {:04d} ,loss_train: {:.4f},acc_train: {:.4f}\\n'.format(epoch+1,loss_train,acc_train),end=\"\")\n",
    "\n",
    "        if not fast_training:\n",
    "\n",
    "            loss_val,acc_val=evaluate(idx_val)\n",
    "            validation_loss_list.append(loss_val)\n",
    "            validation_error_list.append(1-acc_val)\n",
    "\n",
    "           #print('Eval: ,loss_val: {:.4f},acc_val: {:.4f}\\n'.format(loss_val,acc_val),end=\"\")\n",
    "            if loss_val<min_val_loss:\n",
    "              epoch_no_improvement=0\n",
    "              min_val_loss = loss_val\n",
    "            else:\n",
    "              epoch_no_improvement+=1\n",
    "\n",
    "            if epoch_no_improvement==early_stop_epoch:\n",
    "              print('Early Stop at Epoch %d'%(epoch))\n",
    "              break\n",
    "            #print()\n",
    "\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Total Training time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "\n",
    "    #test\n",
    "    print(\"Start Inference:\")\n",
    "\n",
    "\n",
    "    loss_trn,acc_trn=evaluate(idx_train)\n",
    "    print('Train:','loss;: {:.4f}'.format( loss_trn),\n",
    "              'acc: {:.4f}'.format(acc_trn))\n",
    "\n",
    "\n",
    "    t_total = time.time()\n",
    "    loss_test,acc_test=evaluate(idx_test)\n",
    "    print('Test:','loss;: {:.4f}'.format( loss_test),\n",
    "              'acc: {:.4f}'.format(acc_test))\n",
    "    print(\"Total Inference time elapsed: {:.4f}s\".format(time.time() - t_total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "github_user\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7ae2df3e1643289cc67290b67c580c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stop at Epoch 227\n",
      "Optimization Finished!\n",
      "Total Training time elapsed: 517.7949s\n",
      "Start Inference:\n",
      "Train: loss;: 0.4439 acc: 0.7762\n",
      "Test: loss;: 0.5156 acc: 0.7507\n",
      "Total Inference time elapsed: 1.0861s\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN with ResCon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def train(idx_train):\n",
    "  \n",
    "    model.train()\n",
    "   \n",
    "    output = model(features)\n",
    "    \n",
    "    loss_train=loss(output,labels,idx_train)\n",
    "    acc_train = accuracy(output, labels,idx_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss_train.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "   \n",
    "    return loss_train.item(),acc_train.item()\n",
    "\n",
    "\n",
    "def evaluate(idx):\n",
    "    model.eval()\n",
    "    output = model(features)\n",
    "    loss_ =loss(output,labels,idx)\n",
    "    acc_ = accuracy(output, labels,idx)\n",
    "\n",
    "    return loss_.item(),acc_.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cora\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032e5abe8115430cbdc94b6bbeb723ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stop at Epoch 153\n",
      "Optimization Finished!\n",
      "Total Training time elapsed: 4.7659s\n",
      "Start Inference:\n",
      "Train: loss;: 0.0437 acc: 1.0000\n",
      "Test: loss;: 0.7461 acc: 0.7770\n",
      "Total Inference time elapsed: 0.0120s\n",
      "\n",
      "citeseer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e74b39ca086e4fa0a69877878b3fc5da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stop at Epoch 163\n",
      "Optimization Finished!\n",
      "Total Training time elapsed: 17.1050s\n",
      "Start Inference:\n",
      "Train: loss;: 0.0586 acc: 1.0000\n",
      "Test: loss;: 0.9238 acc: 0.7170\n",
      "Total Inference time elapsed: 0.0439s\n",
      "\n",
      "pubmed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc00a89b97146faab2a253b586fde51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stop at Epoch 69\n",
      "Optimization Finished!\n",
      "Total Training time elapsed: 9.4488s\n",
      "Start Inference:\n",
      "Train: loss;: 0.0334 acc: 1.0000\n",
      "Test: loss;: 0.6090 acc: 0.7650\n",
      "Total Inference time elapsed: 0.0575s\n"
     ]
    }
   ],
   "source": [
    "DATASET=['cora','citeseer','pubmed']\n",
    "\n",
    "no_cuda= False,\n",
    "seed=42\n",
    "epochs=400\n",
    "lr=0.01\n",
    "weight_decay=5e-4\n",
    "hidden=32\n",
    "dropout=0.5\n",
    "fast_training=False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
    "early_stop_epoch=10\n",
    "\n",
    "\n",
    "for dataset_str in DATASET:\n",
    "    print()\n",
    "    print(dataset_str)\n",
    "    G,A_norm, features, labels, idx_train,idx_test,idx_val=load_data(dataset_str)\n",
    "\n",
    "    model = MutipleGCN(adj=A_norm,ngcu=2,nfeat=features.shape[1],\n",
    "                nhid=hidden,\n",
    "                nclass=labels.max().item() + 1,\n",
    "                dropout=dropout,res_connection=True).to(device=device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "\n",
    "    # Train model\n",
    "    t_total = time.time()\n",
    "    epoch_no_improvement=0\n",
    "    min_val_loss=float('inf')\n",
    "\n",
    "    init_loss_train, init_acc_train=evaluate(idx_train)\n",
    "    training_loss_list=[init_loss_train]\n",
    "    training_error_list=[1-init_acc_train]\n",
    "\n",
    "    if not fast_training:\n",
    "        init_loss_val, init_acc_val=evaluate(idx_val)\n",
    "        validation_loss_list=[init_loss_val]\n",
    "        validation_error_list=[1-init_acc_val]\n",
    "\n",
    "    for epoch in tqdm_notebook(range(epochs)):\n",
    "\n",
    "        loss_train,acc_train=train(idx_train)\n",
    "        training_loss_list.append(loss_train)\n",
    "        training_error_list.append(1-acc_train)\n",
    "        #print('Epoch: {:04d} ,loss_train: {:.4f},acc_train: {:.4f}\\n'.format(epoch+1,loss_train,acc_train),end=\"\")\n",
    "\n",
    "        if not fast_training:\n",
    "\n",
    "            loss_val,acc_val=evaluate(idx_val)\n",
    "            validation_loss_list.append(loss_val)\n",
    "            validation_error_list.append(1-acc_val)\n",
    "\n",
    "           #print('Eval: ,loss_val: {:.4f},acc_val: {:.4f}\\n'.format(loss_val,acc_val),end=\"\")\n",
    "            if loss_val<min_val_loss:\n",
    "              epoch_no_improvement=0\n",
    "              min_val_loss = loss_val\n",
    "            else:\n",
    "              epoch_no_improvement+=1\n",
    "\n",
    "            if epoch_no_improvement==early_stop_epoch:\n",
    "              print('Early Stop at Epoch %d'%(epoch))\n",
    "              break\n",
    "            #print()\n",
    "\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Total Training time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "\n",
    "    #test\n",
    "    print(\"Start Inference:\")\n",
    "\n",
    "\n",
    "    loss_trn,acc_trn=evaluate(idx_train)\n",
    "    print('Train:','loss;: {:.4f}'.format( loss_trn),\n",
    "              'acc: {:.4f}'.format(acc_trn))\n",
    "\n",
    "\n",
    "    t_total = time.time()\n",
    "    loss_test,acc_test=evaluate(idx_test)\n",
    "    print('Test:','loss;: {:.4f}'.format( loss_test),\n",
    "              'acc: {:.4f}'.format(acc_test))\n",
    "    print(\"Total Inference time elapsed: {:.4f}s\".format(time.time() - t_total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "github_user\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3606c7a006478b871336148929ec94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stop at Epoch 24\n",
      "Optimization Finished!\n",
      "Total Training time elapsed: 62.7231s\n",
      "Start Inference:\n",
      "Train: loss;: 0.4436 acc: 0.7420\n",
      "Test: loss;: 0.5730 acc: 0.7416\n",
      "Total Inference time elapsed: 1.1013s\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cuda= False,\n",
    "seed=42\n",
    "epochs=200\n",
    "lr=0.005\n",
    "weight_decay=1e-3\n",
    "hidden=8\n",
    "dropout=0.6\n",
    "fast_training=False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
    "early_stop_epoch=10\n",
    "nheads=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9df1ffb43be4bd1ad8404bfbafbd1e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization Finished!\n",
      "Total Training time elapsed: 52.2657s\n",
      "Start Inference:\n",
      "Train: loss;: 0.2831 acc: 0.9929\n",
      "Test: loss;: 0.8154 acc: 0.8150\n",
      "Total Inference time elapsed: 0.0556s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1f63f5c0ad41259ace935e966d0ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization Finished!\n",
      "Total Training time elapsed: 104.6717s\n",
      "Start Inference:\n",
      "Train: loss;: 0.4135 acc: 1.0000\n",
      "Test: loss;: 1.1639 acc: 0.6990\n",
      "Total Inference time elapsed: 0.0592s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f097f3305c3148b7af8c0d73ec661653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stop at Epoch 138\n",
      "Optimization Finished!\n",
      "Total Training time elapsed: 883.8949s\n",
      "Start Inference:\n",
      "Train: loss;: 0.1630 acc: 1.0000\n",
      "Test: loss;: 0.6077 acc: 0.7740\n",
      "Total Inference time elapsed: 0.1997s\n"
     ]
    }
   ],
   "source": [
    "for dataset_str in DATASET:\n",
    "\n",
    "    G,_, features, labels, idx_train,idx_test,idx_val=load_data(dataset_str)\n",
    "    A= get_adjacency_matrix(G)\n",
    "    A=A + sparse.eye(A.shape[0])\n",
    "    A_norm=sparse_mx_to_torch_sparse_tensor(A)\n",
    "\n",
    "\n",
    "    model = GAT(adj=A_norm,nheads=nheads,nfeat=features.shape[1],\n",
    "                nhid=hidden,\n",
    "                nclass=labels.max().item() + 1,\n",
    "                dropout=dropout,res_connection=True,last_layer_mh=False).to(device=device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "\n",
    "    # Train model\n",
    "    t_total = time.time()\n",
    "    epoch_no_improvement=0\n",
    "    min_val_loss=float('inf')\n",
    "\n",
    "    init_loss_train, init_acc_train=evaluate(idx_train)\n",
    "    training_loss_list=[init_loss_train]\n",
    "    training_error_list=[1-init_acc_train]\n",
    "\n",
    "    if not fast_training:\n",
    "        init_loss_val, init_acc_val=evaluate(idx_val)\n",
    "        validation_loss_list=[init_loss_val]\n",
    "        validation_error_list=[1-init_acc_val]\n",
    "\n",
    "    for epoch in tqdm_notebook(range(epochs)):\n",
    "\n",
    "        loss_train,acc_train=train(idx_train)\n",
    "        training_loss_list.append(loss_train)\n",
    "        training_error_list.append(1-acc_train)\n",
    "        #print('Epoch: {:04d} ,loss_train: {:.4f},acc_train: {:.4f}\\n'.format(epoch+1,loss_train,acc_train),end=\"\")\n",
    "\n",
    "        if not fast_training:\n",
    "\n",
    "            loss_val,acc_val=evaluate(idx_val)\n",
    "            validation_loss_list.append(loss_val)\n",
    "            validation_error_list.append(1-acc_val)\n",
    "\n",
    "           #print('Eval: ,loss_val: {:.4f},acc_val: {:.4f}\\n'.format(loss_val,acc_val),end=\"\")\n",
    "            if loss_val<min_val_loss:\n",
    "              epoch_no_improvement=0\n",
    "              min_val_loss = loss_val\n",
    "            else:\n",
    "              epoch_no_improvement+=1\n",
    "\n",
    "            if epoch_no_improvement==early_stop_epoch:\n",
    "              print('Early Stop at Epoch %d'%(epoch))\n",
    "              break\n",
    "            #print()\n",
    "\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Total Training time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "\n",
    "    #test\n",
    "    print(\"Start Inference:\")\n",
    "\n",
    "\n",
    "    loss_trn,acc_trn=evaluate(idx_train)\n",
    "    print('Train:','loss;: {:.4f}'.format( loss_trn),\n",
    "              'acc: {:.4f}'.format(acc_trn))\n",
    "\n",
    "\n",
    "    t_total = time.time()\n",
    "    loss_test,acc_test=evaluate(idx_test)\n",
    "    print('Test:','loss;: {:.4f}'.format( loss_test),\n",
    "              'acc: {:.4f}'.format(acc_test))\n",
    "    print(\"Total Inference time elapsed: {:.4f}s\".format(time.time() - t_total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cuda= False,\n",
    "seed=42\n",
    "epochs=200\n",
    "lr=0.005\n",
    "weight_decay=1e-3\n",
    "hidden=8\n",
    "dropout=0.6\n",
    "fast_training=False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
    "early_stop_epoch=10\n",
    "nheads=8\n",
    "DATASET=['github_user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963703d751ce4da9b10a9a23c4f4d302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-aab4f03e8912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mtraining_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtraining_error_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0macc_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-61af773854df>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(idx_train)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0macc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for dataset_str in DATASET:\n",
    "\n",
    "    G,_, features, labels, idx_train,idx_test,idx_val=load_data(dataset_str)\n",
    "    A= get_adjacency_matrix(G)\n",
    "    A=A + sparse.eye(A.shape[0])\n",
    "    A_norm=sparse_mx_to_torch_sparse_tensor(A)\n",
    "\n",
    "\n",
    "    model = GAT(adj=A_norm,nheads=nheads,nfeat=features.shape[1],\n",
    "                nhid=hidden,\n",
    "                nclass=labels.max().item() + 1,\n",
    "                dropout=dropout,res_connection=True,last_layer_mh=False).to(device=device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "\n",
    "    # Train model\n",
    "    t_total = time.time()\n",
    "    epoch_no_improvement=0\n",
    "    min_val_loss=float('inf')\n",
    "\n",
    "    init_loss_train, init_acc_train=evaluate(idx_train)\n",
    "    training_loss_list=[init_loss_train]\n",
    "    training_error_list=[1-init_acc_train]\n",
    "\n",
    "    if not fast_training:\n",
    "        init_loss_val, init_acc_val=evaluate(idx_val)\n",
    "        validation_loss_list=[init_loss_val]\n",
    "        validation_error_list=[1-init_acc_val]\n",
    "\n",
    "    for epoch in tqdm_notebook(range(epochs)):\n",
    "\n",
    "        loss_train,acc_train=train(idx_train)\n",
    "        training_loss_list.append(loss_train)\n",
    "        training_error_list.append(1-acc_train)\n",
    "        #print('Epoch: {:04d} ,loss_train: {:.4f},acc_train: {:.4f}\\n'.format(epoch+1,loss_train,acc_train),end=\"\")\n",
    "\n",
    "        if not fast_training:\n",
    "\n",
    "            loss_val,acc_val=evaluate(idx_val)\n",
    "            validation_loss_list.append(loss_val)\n",
    "            validation_error_list.append(1-acc_val)\n",
    "\n",
    "           #print('Eval: ,loss_val: {:.4f},acc_val: {:.4f}\\n'.format(loss_val,acc_val),end=\"\")\n",
    "            if loss_val<min_val_loss:\n",
    "              epoch_no_improvement=0\n",
    "              min_val_loss = loss_val\n",
    "            else:\n",
    "              epoch_no_improvement+=1\n",
    "\n",
    "            if epoch_no_improvement==early_stop_epoch:\n",
    "              print('Early Stop at Epoch %d'%(epoch))\n",
    "              break\n",
    "            #print()\n",
    "\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Total Training time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "\n",
    "    #test\n",
    "    print(\"Start Inference:\")\n",
    "\n",
    "\n",
    "    loss_trn,acc_trn=evaluate(idx_train)\n",
    "    print('Train:','loss;: {:.4f}'.format( loss_trn),\n",
    "              'acc: {:.4f}'.format(acc_trn))\n",
    "\n",
    "\n",
    "    t_total = time.time()\n",
    "    loss_test,acc_test=evaluate(idx_test)\n",
    "    print('Test:','loss;: {:.4f}'.format( loss_test),\n",
    "              'acc: {:.4f}'.format(acc_test))\n",
    "    print(\"Total Inference time elapsed: {:.4f}s\".format(time.time() - t_total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting of Neural Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def train(idx_train):\n",
    "  \n",
    "    model.train()\n",
    "   \n",
    "    output = model(features)\n",
    "    \n",
    "    loss_train=loss(output,labels,idx_train)\n",
    "    acc_train = accuracy(output, labels,idx_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss_train.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "   \n",
    "    return loss_train.item(),acc_train.item()\n",
    "\n",
    "\n",
    "def evaluate(idx):\n",
    "    model.eval()\n",
    "    output = model(features)\n",
    "    loss_ =loss(output,labels,idx)\n",
    "    acc_ = accuracy(output, labels,idx)\n",
    "\n",
    "    return loss_.item(),acc_.item()\n",
    "\n",
    "\n",
    "def train_model():\n",
    "    # Train model\n",
    "    training_loss_list=[]\n",
    "    training_error_list=[]\n",
    "    validation_loss_list=[]\n",
    "    validation_error_list=[]\n",
    "        \n",
    "    t_total = time.time()\n",
    "    epoch_no_improvement=0\n",
    "    min_val_loss=float('inf')\n",
    "\n",
    "    init_loss_train, init_acc_train=evaluate(idx_train)\n",
    "    training_loss_list=[init_loss_train]\n",
    "    training_error_list=[1-init_acc_train]\n",
    "\n",
    "    if not fast_training:\n",
    "        init_loss_val, init_acc_val=evaluate(idx_val)\n",
    "        validation_loss_list=[init_loss_val]\n",
    "        validation_error_list=[1-init_acc_val]\n",
    "\n",
    "    for epoch in tqdm_notebook(range(epochs)):\n",
    "\n",
    "        loss_train,acc_train=train(idx_train)\n",
    "        training_loss_list.append(loss_train)\n",
    "        training_error_list.append(1-acc_train)\n",
    "        #print('Epoch: {:04d} ,loss_train: {:.4f},acc_train: {:.4f}\\n'.format(epoch+1,loss_train,acc_train),end=\"\")\n",
    "        loss_val,acc_val=evaluate(idx_val)\n",
    "        validation_loss_list.append(loss_val)\n",
    "        validation_error_list.append(1-acc_val)\n",
    "\n",
    "    return [training_loss_list,validation_loss_list,training_error_list,validation_error_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560e58b26aa64970b88cb1b6027f115f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4720cb8207a44d89b696457f431e2b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a390766fbebc485798555951fcdb7368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed93915b52104b0ab7dc2d92d9b6f7e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8fd7d871d741ccb468be559180d669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4ae5b026b84527b7de30a0e4640940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATASET=['pubmed','github_user']\n",
    "\n",
    "\n",
    "no_cuda= False,\n",
    "seed=42\n",
    "epochs=200\n",
    "lr=0.01\n",
    "weight_decay=5e-4\n",
    "hidden=16\n",
    "dropout=0.6\n",
    "fast_training=False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
    "early_stop_epoch=10000\n",
    "nheads=8\n",
    "\n",
    "\n",
    "names=['GCN','GCN (residual)','GAT']\n",
    "color_list=['red','green','blue']\n",
    "\n",
    "for dataset_str in DATASET:\n",
    "    plt.figure(figsize=(18,4))\n",
    "\n",
    "    ax1=plt.subplot(141)\n",
    "    ax2=plt.subplot(142)\n",
    "    ax3=plt.subplot(143)\n",
    "    ax4=plt.subplot(144)\n",
    "    axes=[ax1,ax2,ax3,ax4]\n",
    "    for  model_index in range(3):\n",
    "        if model_index==0:\n",
    "  \n",
    "            G,A_norm, features, labels, idx_train,idx_test,idx_val=load_data(dataset_str)\n",
    "            model = MutipleGCN(adj=A_norm,ngcu=2,nfeat=features.shape[1],\n",
    "                        nhid=hidden,\n",
    "                        nclass=labels.max().item() + 1,\n",
    "                        dropout=dropout,res_connection=False).to(device=device)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
    "        elif model_index==1:\n",
    "  \n",
    "            G,A_norm, features, labels, idx_train,idx_test,idx_val=load_data(dataset_str)\n",
    "\n",
    "            model = MutipleGCN(adj=A_norm,ngcu=2,nfeat=features.shape[1],\n",
    "                        nhid=hidden,\n",
    "                        nclass=labels.max().item() + 1,\n",
    "                        dropout=dropout,res_connection=True).to(device=device)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
    "        else:\n",
    "  \n",
    "            G,A_norm, features, labels, idx_train,idx_test,idx_val=load_data(dataset_str)\n",
    "            A= get_adjacency_matrix(G)\n",
    "            A=A + sparse.eye(A.shape[0])\n",
    "            A_norm=sparse_mx_to_torch_sparse_tensor(A)\n",
    "\n",
    "            model = GAT(adj=A_norm,nheads=nheads,nfeat=features.shape[1],\n",
    "                        nhid=hidden,\n",
    "                        nclass=labels.max().item() + 1,\n",
    "                        dropout=dropout,res_connection=True,last_layer_mh=False).to(device=device)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
    "        #train_model    \n",
    "        \n",
    "        trn_statistics=train_model()\n",
    "        x=range(len(trn_statistics[0]))\n",
    "        for j in range(len(trn_statistics)):\n",
    "            axes[j].plot(x, trn_statistics[j], label=names[model_index], marker=None,color=color_list[model_index])\n",
    "    \n",
    "    target_word1=['Loss','Loss','Error','Error']\n",
    "    target_word2=['Training Loss','Validation Loss','Training Error','Validation Error']\n",
    "    for j in range(4):\n",
    "        axes[j].set_xlabel(\"Epoch\")\n",
    "        axes[j].set_ylabel(target_word1[j])\n",
    "        axes[j].title.set_text(target_word2[j])\n",
    "        axes[j].legend(loc=1)\n",
    "        axes[j].set_xticks([0,50,100,150,200])\n",
    "  \n",
    "    plt.suptitle(\"{}\".format(dataset_str.capitalize()),y=-0.01)\n",
    "   \n",
    "    plt.savefig(\"{}_three_model.jpg\".format(dataset_str))\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wall Clock Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "no_cuda= False,\n",
    "seed=42\n",
    "epochs=200\n",
    "lr=0.01\n",
    "weight_decay=5e-4\n",
    "hidden=16\n",
    "dropout=0.6\n",
    "fast_training=False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
    "early_stop_epoch=10000\n",
    "nheads=8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "10\n",
      "20\n",
      "50\n",
      "100\n",
      "200\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "10\n",
      "20\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "def train_model_time(dataset_str,depth=None,res_connection=False):\n",
    "    G,A_norm, features, labels, _,_,_=load_data(dataset_str)\n",
    "    \n",
    "    idx_train=np.arange(len(features))\n",
    "    idx_train=torch.LongTensor(idx_train)\n",
    "    \n",
    "    def train(idx_train): \n",
    "        model.train()\n",
    "\n",
    "        output = model(features)\n",
    "\n",
    "        loss_train=loss(output,labels,idx_train)\n",
    "        acc_train = accuracy(output, labels,idx_train)\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        return loss_train.item(),acc_train.item()\n",
    "    def evaluate(idx):\n",
    "        model.eval()\n",
    "        output = model(features)\n",
    "        loss_ =loss(output,labels,idx)\n",
    "        acc_ = accuracy(output, labels,idx)\n",
    "\n",
    "        return loss_.item(),acc_.item()\n",
    "    \n",
    "\n",
    "    model = MutipleGCN(adj=A_norm,ngcu=depth,nfeat=features.shape[1],\n",
    "                nhid=hidden,\n",
    "                nclass=labels.max().item() + 1,\n",
    "                dropout=dropout,res_connection=res_connection).to(device=device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
    "    \n",
    "    t_start = time.time()\n",
    "    for i in range(10):\n",
    "        loss_train,acc_train=train(idx_train)\n",
    "            \n",
    "    training_time=(time.time() - t_start)/10\n",
    "    \n",
    "    t_start = time.time()\n",
    "    for i in range(10):\n",
    "        loss_val,acc_val=evaluate(idx_train)\n",
    "    \n",
    "    inference_time=(time.time() - t_start)/10\n",
    "    \n",
    "    return training_time,inference_time\n",
    "\n",
    "def plot_runtime_analysis(dataset_str,ndepth_list):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    ax1=plt.subplot(111)\n",
    "\n",
    "\n",
    "    dataset_str=dataset_str\n",
    "    train_with_res_temp=[]\n",
    "    test_with_res_temp=[]\n",
    "    test_without_res_temp=[]\n",
    "    train_without_res_temp=[]\n",
    "    for depth in ndepth_list:\n",
    "        print(depth)\n",
    "\n",
    "        trn_time1,tst_time1=train_model_time(dataset_str,depth=depth,res_connection=True)\n",
    "        \n",
    "        trn_time2,tst_time2=train_model_time(dataset_str,depth=depth,res_connection=False)\n",
    "        \n",
    "        train_with_res_temp.append(trn_time1)\n",
    "        test_with_res_temp.append(tst_time1)\n",
    "        train_without_res_temp.append(trn_time2)\n",
    "        test_without_res_temp.append(tst_time2)\n",
    "\n",
    "\n",
    "    x=range(1,len(ndepth_list)+1)\n",
    "    ax1.plot(x, train_with_res_temp,'g-', label=\"Training (Residual)\",marker='o')\n",
    "    ax1.plot(x, test_with_res_temp,'r-', label=\"Inference (Residual)\", marker='o')\n",
    "    ax1.plot(x, train_without_res_temp,'b--', label=\"Training\", marker='o')\n",
    "    ax1.plot(x, test_without_res_temp,'y--',label=\"Inference\", marker='o')\n",
    "\n",
    "    ax1.set_xlabel(\"Number of Layers\")\n",
    "    ax1.set_ylabel(\"Time\")\n",
    " \n",
    "    ax1.legend(loc=2)\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(ndepth_list)\n",
    "    if dataset_str=='github_user':\n",
    "        ax1.title.set_text('GSN')\n",
    "    else:\n",
    "        ax1.title.set_text(dataset_str.capitalize())\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.savefig(\"run_time_plot_{}.jpg\".format(dataset_str))\n",
    "    #plt.show()\n",
    "    return \n",
    "\n",
    "\n",
    "DATASET=['cora','citeseer','pubmed','github_user']\n",
    "DEPTH_LIST=[1,2,3,4,5,10,20,50,100,200]\n",
    "\n",
    "for name in DATASET:\n",
    "    plot_runtime_analysis(dataset_str=name,ndepth_list=DEPTH_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gat_model(dataset_str,depth,res_connection=False):\n",
    "    G,A_norm, features, labels, _,_,_=load_data(dataset_str)\n",
    "    \n",
    "    idx_train=np.arange(len(features))\n",
    "    idx_train=torch.LongTensor(idx_train)\n",
    "    \n",
    "    def train(idx_train): \n",
    "        model.train()\n",
    "\n",
    "        output = model(features)\n",
    "\n",
    "        loss_train=loss(output,labels,idx_train)\n",
    "        acc_train = accuracy(output, labels,idx_train)\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        return loss_train.item(),acc_train.item()\n",
    "    def evaluate(idx):\n",
    "        model.eval()\n",
    "        output = model(features)\n",
    "        loss_ =loss(output,labels,idx)\n",
    "        acc_ = accuracy(output, labels,idx)\n",
    "\n",
    "        return loss_.item(),acc_.item()\n",
    "    \n",
    "    A= get_adjacency_matrix(G)\n",
    "    A=A + sparse.eye(A.shape[0])\n",
    "    A_norm=sparse_mx_to_torch_sparse_tensor(A)\n",
    "\n",
    "    model = GAT(adj=A_norm,nheads=depth,nfeat=features.shape[1],\n",
    "                nhid=hidden,\n",
    "                nclass=labels.max().item() + 1,\n",
    "                dropout=dropout,res_connection=True,last_layer_mh=False).to(device=device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
    "    \n",
    "    t_start = time.time()\n",
    "    for i in range(10):\n",
    "        loss_train,acc_train=train(idx_train)\n",
    "            \n",
    "    training_time=(time.time() - t_start)/10\n",
    "    \n",
    "    t_start = time.time()\n",
    "    for i in range(10):\n",
    "        loss_val,acc_val=evaluate(idx_train)\n",
    "    \n",
    "    inference_time=(time.time() - t_start)/10\n",
    "    \n",
    "    return training_time,inference_time    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "8\n",
      "10\n",
      "15\n",
      "20\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def plot_runtime_analysis_forGAT(dataset_str,ndepth_list):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    ax1=plt.subplot(111)\n",
    "\n",
    "    dataset_str=dataset_str\n",
    "    test_without_res_temp=[]\n",
    "    train_without_res_temp=[]\n",
    "    for depth in ndepth_list:\n",
    "        print(depth)\n",
    "\n",
    "        trn_time1,tst_time1=train_gat_model(dataset_str,depth=depth,res_connection=False)\n",
    "      \n",
    "        \n",
    "        train_without_res_temp.append(trn_time1)\n",
    "        test_without_res_temp.append(tst_time1)\n",
    "   \n",
    "\n",
    "    x=range(1,len(ndepth_list)+1)\n",
    "\n",
    "    ax1.plot(x, train_without_res_temp,'b--', label=\"Training\", marker='o')\n",
    "    ax1.plot(x, test_without_res_temp,'y--',label=\"Inference\", marker='o')\n",
    "\n",
    "    ax1.set_xlabel(\"Number of Attention Heads\")\n",
    "    ax1.set_ylabel(\"Time\")\n",
    "    if dataset_str=='github_user':\n",
    "        ax1.title.set_text('GSN')\n",
    "    else:\n",
    "        ax1.title.set_text(dataset_str.capitalize())\n",
    "    ax1.legend(loc=2)\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(ndepth_list)\n",
    "    \n",
    "    \n",
    "    plt.savefig(\"run_time_plot_GAT_{}.jpg\".format(dataset_str))\n",
    "    plt.show()\n",
    "    return \n",
    "DATASET=['cora','citeseer','pubmed','github_user']\n",
    "DEPTH_LIST=[1,2,3,4,5,8,10,15,20]\n",
    "\n",
    "for name in DATASET:\n",
    "    plot_runtime_analysis_forGAT(dataset_str=name,ndepth_list=DEPTH_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
